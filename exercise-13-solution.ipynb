{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "qK1kecVF2afc"
   },
   "source": [
    "<div style=\"font-size:1.4em; margin-bottom:2em\">\n",
    "    <div style=\"float:right; line-height:1.2em;\">GET Lab<br />Paderborn University</div>\n",
    "  <div>SS 2021</div>\n",
    "</div>\n",
    "<div style=\"clear:both\"></div>\n",
    "<div style=\"text-align:center; font-size:1.8em;\">\n",
    "  Digital Image Processing II<br />Task Sheet 13\n",
    "</div>\n",
    "\n",
    "<hr>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Overview"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The objective of this task sheet is to implement and test a neural network to solve the XOR problem. This problem cannot be solved using a single linear decision boundary. The XOR problem is formed by assigning the XOR false values to one class ($c_1$), and the truth values to another ($c_2$). In this example, the binary coordinates have been rearranged for mathematical convenience. Note that in the neural network, the bias is not explicitly displayed with an additional arrow (which is usual) and that each neuron (node) has only a single output value which is send to all neurons in the next layer.\n",
    "\n",
    "The following figure shows the XOR problem to be studied, the fully connected neural network to be used, and the activation function to be used:\n",
    "\n",
    "<center><img src=\"images/overview.png\" width=\"850px\" style=\"margin:10px;\" /></center>\n",
    "\n",
    "Backpropagation, and therefore the training of neural networks, is usually formalized in terms of a matrix formulation. This leads to compact and easy to implement computations. Each layer is assigned an index $\\ell$. The training feature vectors (patterns) are summarized in a single pattern matrix $\\mathbf{X}$, where each column represents one pattern. The desired classification (the ideal activation values of the output neurons) is represented by the class membership matrix $\\mathbf{R}$. The matrices are given as follows:\n",
    "\n",
    "$$\n",
    "\\mathbf{X} =\n",
    "\\begin{bmatrix}\n",
    "1 & -1 & -1 &  1\\\\\n",
    "1 & -1 &  1 & -1\n",
    "\\end{bmatrix},\\\n",
    "\\mathbf{R} =\n",
    "\\begin{bmatrix}\n",
    "1 & 1 & 0 & 0\\\\\n",
    "0 & 0 & 1 & 1\n",
    "\\end{bmatrix}\n",
    "$$\n",
    "\n",
    "The input weights of each layer are summarized in a weight matrix $\\mathbf{M}(\\ell)$ and the bias values in a bias vector $\\mathbf{b}(\\ell)$. For $n_p$ training patterns (we have $n_p = 4$), $\\mathbf{b}(\\ell)$ has to be concatenated $n_p$ times in the horizontal direction to form a matrix $\\mathbf{B}(\\ell)$. In this example, we get the following forms:\n",
    "\n",
    "$$\n",
    "\\mathbf{W}(\\ell) =\n",
    "\\begin{bmatrix}\n",
    "w_{11}(\\ell) & w_{12}(\\ell)\\\\\n",
    "w_{21}(\\ell) & w_{22}(\\ell)\n",
    "\\end{bmatrix},\\\n",
    "\\mathbf{b}(\\ell) =\n",
    "\\begin{bmatrix}\n",
    "b_1(\\ell)\\\\\n",
    "b_2(\\ell)\n",
    "\\end{bmatrix},\\\n",
    "\\mathbf{B}(\\ell) =\n",
    "\\begin{bmatrix}\n",
    "b_1(\\ell) & b_1(\\ell) & b_1(\\ell) & b_1(\\ell)\\\\\n",
    "b_2(\\ell) & b_2(\\ell) & b_2(\\ell) & b_2(\\ell)\n",
    "\\end{bmatrix}\n",
    "$$\n",
    "\n",
    "As shown in the figure above, the weights $w_{ij}(\\ell)$ are notated as follows: the index $i$ refers to the number of the input neuron in that layer (layer $\\ell$) and $j$ to the number of the sending neuron in the previous layer ($\\ell-1$). The net inputs of the neurons for all feature vectors in one layer are summarized in a matrix $\\mathbf{Z}(\\ell)$. The corresponding activation values are summarized in a matrix $\\mathbf{A}(\\ell) = h(\\mathbf{Z}(\\ell))$, where $h(\\cdot)$ denotes the activation function. The activation function is applied separately to each element of $\\mathbf{Z}(\\ell)$. Each column of $\\mathbf{A}(\\ell)$ represents the activation values of the neurons in layer $\\ell$ for the corresponding training pattern (the corresponding column in $\\mathbf{X}$). The backpropagated errors are summarized in a matrix $\\mathbf{D}(\\ell)$. The learning rate is denoted by $\\alpha$.\n",
    "\n",
    "The backpropagation algorithm for one epoch can then be summarized as follows, where $\\odot$ refers to elementwise multiplication (carefully look for $\\ell$ and $L$):\n",
    "\n",
    "<center><img src=\"images/backpropagation.png\" width=\"700px\" style=\"margin:10px;\" /></center>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "from matplotlib import pyplot as plt\n",
    "\n",
    "dpi = plt.rcParams['figure.dpi']\n",
    "\n",
    "# plot image in original size\n",
    "def plot_img_orig(img):\n",
    "    fig = plt.figure(figsize = (img.shape[1]/dpi, img.shape[0]/dpi))\n",
    "    fig.add_axes([0, 0, 1, 1])\n",
    "    plt.axis('off')\n",
    "    plt.imshow(img, cmap='gray', vmin=0, vmax=255) # cmap parameter is ignored for RGB(A) data\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### <span style=\"color: RoyalBlue; font-weight: bold;\">Task 13.1</span> Fully Connected Neural Networks and Backpropagation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Implement / solve the following tasks:\n",
    "1. Implement the neural network from the overview and train it with the four given training patterns using the backpropagation algorithm.\n",
    "2. Print and analyze the activation matrix $\\mathbf{A}(3)$ of the output layer after an appropriate number of epochs. Does it converge?\n",
    "3. Use the trained network to classify regularly sampled patterns in the 2D plane and plot the result.\n",
    "4. Plot and analyze the corresponding activation values of the first output neuron, for example by using a grayvalue image."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Desired result:\n",
      "[[1 1 0 0]\n",
      " [0 0 1 1]]\n",
      "\n",
      "Result for epoch 0:\n",
      "[[0.4984994  0.55885515 0.39728459 0.65650188]\n",
      " [0.83815994 0.88931122 0.95943112 0.63649247]]\n",
      "\n",
      "Result for epoch 100:\n",
      "[[0.79574991 0.7957506  0.26183939 0.19494975]\n",
      " [0.16209913 0.16210259 0.7473101  0.87850316]]\n",
      "\n",
      "Result for epoch 200:\n",
      "[[0.89578842 0.89578786 0.13132748 0.10149223]\n",
      " [0.09179856 0.09179913 0.87669884 0.91554536]]\n",
      "\n",
      "Result for epoch 300:\n",
      "[[0.92369739 0.92369721 0.0953027  0.0749044 ]\n",
      " [0.07013714 0.07013733 0.90943289 0.93297216]]\n",
      "\n",
      "Result for epoch 400:\n",
      "[[0.93748453 0.93748444 0.07772762 0.06160881]\n",
      " [0.0586989  0.05869899 0.92546099 0.94308484]]\n",
      "\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 360x360 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Decision surface:\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAR4AAAEeCAYAAABcyXrWAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADh0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uMy4yLjEsIGh0dHA6Ly9tYXRwbG90bGliLm9yZy+j8jraAAAFAklEQVR4nO3dwUkjUBSG0YmahViCay3GBqzEolzah9iBK0sQwY3JVJAHw2W+GD1nGx64iB8XhN/Nfr//A1A6O/YPAPw+wgPkhAfICQ+QEx4gJzxA7mL14Xa79bf2X2yz2Yzen5+fj95fXl6O3l9fX4/e393djd7f39+P3t/c3IzeX11djd6fnY3vkoNfIBcPkBMeICc8QE54gJzwADnhAXLCA+SEB8gJD5ATHiAnPEBOeICc8AA54QFywgPklns8nDZ7OvZ0Jqb/+mr1/XPxADnhAXLCA+SEB8gJD5ATHiAnPEBOeICc8AA54QFywgPkhAfICQ+QEx4gJzxAzh7PN2ZPx57OxHRP5/Pzc/R+9f1x8QA54QFywgPkhAfICQ+QEx4gJzxATniAnPAAOeEBcsID5IQHyAkPkBMeICc8QM4ez39kT8eezsSx93Te3t5G729vbw9+5uIBcsID5IQHyAkPkBMeICc8QE54gJzwADnhAXLCA+SEB8gJD5ATHiAnPEBOeICcPZ4Fezr2dCZOfU/n6elp9P7h4eHgZy4eICc8QE54gJzwADnhAXLCA+SEB8gJD5ATHiAnPEBOeICc8AA54QFywgPkhAfIbVabIdvtdjYocmT2dOzpTPz2PZ3Hx8fR++fn54O/gC4eICc8QE54gJzwADnhAXLCA+SEB8gJD5ATHiAnPEBOeICc8AA54QFywgPkhAfIXRz7B1ixp2NPZ8KezmxP5/X1dfR+xcUD5IQHyAkPkBMeICc8QE54gJzwADnhAXLCA+SEB8gJD5ATHiAnPEBOeICc8AC5/7rHY0/Hns6EPZ3j7ul8fHyM3q+4eICc8AA54QFywgPkhAfICQ+QEx4gJzxATniAnPAAOeEBcsID5IQHyAkPkBMeILfc47GnY09nwp7Oae/pfH19jd6vuHiAnPAAOeEBcsID5IQHyAkPkBMeICc8QE54gJzwADnhAXLCA+SEB8gJD5ATHiC33OOxp2NPZ8Kezmnv6ex2u9H7FRcPkBMeICc8QE54gJzwADnhAXLCA+SEB8gJD5ATHiAnPEBOeICc8AA54QFywgPklns89nTs6UzY0/m5ezpTLh4gJzxATniAnPAAOeEBcsID5IQHyAkPkBMeICc8QE54gJzwADnhAXLCA+SEB8gt93js6djTmbCn83P3dKZcPEBOeICc8AA54QFywgPkhAfICQ+QEx4gJzxATniAnPAAOeEBcsID5IQHyAkPkFvu8djTsaczYU/n5+7pTLl4gJzwADnhAXLCA+SEB8gJD5ATHiAnPEBOeICc8AA54QFywgPkhAfICQ+QEx4gt1ltxry8vIwGZezp2NOZsKdz2vb7/ebQZy4eICc8QE54gJzwADnhAXLCA+SEB8gJD5ATHiAnPEBOeICc8AA54QFywgPkhAfILfd43t/fR4M09nTs6UzY0zlt9niAb0V4gJzwADnhAXLCA+SEB8gJD5ATHiAnPEBOeICc8AA54QFywgPkhAfICQ+QW+7x7Ha70aCNPR17OhP2dE6bPR7gWxEeICc8QE54gJzwADnhAXLCA+SEB8gJD5ATHiAnPEBOeICc8AA54QFywgPkLlYf2tOxpzNhT4dDXDxATniAnPAAOeEBcsID5IQHyAkPkBMeICc8QE54gJzwADnhAXLCA+SEB8gJD5DbTDdzAP6ViwfICQ+QEx4gJzxATniAnPAAub9AGHRe6LgyTgAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<Figure size 272x272 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# write your code here\n",
    "\n",
    "# parameters\n",
    "alpha = 1.0\n",
    "n_epochs = 500\n",
    "\n",
    "# sigmoid activation function\n",
    "def sigmoid(z):\n",
    "    return 1/(1+np.exp(-z))\n",
    "\n",
    "# derivative of the sigmoid activation function \n",
    "def sigmoid_diff(z):\n",
    "    return sigmoid(z)*(1-sigmoid(z))\n",
    "\n",
    "# random initialization of the weight and bias matrices\n",
    "# layer 2\n",
    "W2 = np.array([[0.18, -0.87], [-0.72, 0.41]])\n",
    "b2 = np.array([0.01, 0.01]).reshape(2, 1) # reshape to get column vector\n",
    "B2 = np.hstack((b2, b2, b2, b2))\n",
    "\n",
    "# layer 3 (output layer, l = L)\n",
    "W3 = np.array([[1.18, -0.97], [-0.72, 4.41]])\n",
    "b3 = np.array([0.01, 0.01]).reshape(2, 1) # reshape to get column vector\n",
    "B3 = np.hstack((b3, b3, b3, b3))\n",
    "\n",
    "# step 1: input patterns and desired output\n",
    "A1 = np.array([[1, -1, -1, 1], [1, -1, 1, -1]])\n",
    "R = np.array([[1, 1, 0, 0], [0, 0, 1, 1]]) # top row: c1, bottom row: c2\n",
    "#print(A1)\n",
    "\n",
    "# print the desired classification matrix\n",
    "print(\"Desired result:\"); print(str(R) + \"\\n\")\n",
    "\n",
    "# k indicates the current epoch\n",
    "for k in range(n_epochs):\n",
    "    # step 2: forward pass\n",
    "    # layer 2\n",
    "    Z2 = (W2 @ A1) + B2\n",
    "    A2 = sigmoid(Z2)\n",
    "    h_diff_Z2 = sigmoid_diff(Z2)\n",
    "\n",
    "    # layer 3 (output layer)\n",
    "    Z3 = (W3 @ A2) + B3\n",
    "    A3 = sigmoid(Z3)\n",
    "    h_diff_Z3 = sigmoid_diff(Z3)\n",
    "\n",
    "    D3 = np.multiply((A3-R), h_diff_Z3) # elementwise multiplication\n",
    "\n",
    "    # step 3: backpropagation - only required for layer 2 here\n",
    "    D2 = np.multiply((np.transpose(W3) @ D3), h_diff_Z2)\n",
    "\n",
    "    # step 4: update weights and biases\n",
    "    # layer 2\n",
    "    W2 = W2 - alpha * D2 @ np.transpose(A1)\n",
    "    b2 = b2 - alpha * (np.sum(D2, axis=1)).reshape(2, 1) # second part gives row vector without reshape\n",
    "    B2 = np.hstack((b2, b2, b2, b2))\n",
    "\n",
    "    # layer 3\n",
    "    W3 = W3 - alpha * D3 @ np.transpose(A2)\n",
    "    b3 = b3 - alpha * (np.sum(D3, axis=1)).reshape(2, 1) # second part gives row vector without reshape\n",
    "    B3 = np.hstack((b3, b3, b3, b3))\n",
    "    \n",
    "    # optional: print last activation values\n",
    "    if (k % 100) == 0:\n",
    "        print(\"Result for epoch \" + str(k) + \":\")\n",
    "        print(str(A3) + \"\\n\")\n",
    "        \n",
    "# regularly sampled patterns in the 2D plane\n",
    "pos = np.arange(-2, 2.25, 0.25) # to generate pairs of x1 and x2\n",
    "\n",
    "# plot preparation\n",
    "plt.figure(figsize=(5, 5))\n",
    "plt.xlabel(\"$x_1$\"); plt.ylabel(\"$x_2$\")\n",
    "plt.axis(\"equal\")\n",
    "plt.xlim(-2, 2); plt.ylim(-2, 2)\n",
    "\n",
    "# image to visualize the activation value of the first neuron\n",
    "img = np.zeros((len(pos), len(pos)))\n",
    "\n",
    "# classify each pair (pattern) of x1 and x2 \n",
    "for i in range (len(pos)):\n",
    "    for j in range (len(pos)):\n",
    "        # input pattern\n",
    "        A1 = np.array([pos[i], pos[j]]).reshape(2, 1)\n",
    "        \n",
    "        # forward pass through layer 2\n",
    "        Z2 = (W2 @ A1) + b2 # note that b2 is a single col vector\n",
    "        A2 = sigmoid(Z2)\n",
    "\n",
    "        # forward pass through layer 3 (output layer)\n",
    "        Z3 = (W3 @ A2) + b3\n",
    "        A3 = sigmoid(Z3)\n",
    "        \n",
    "        # save the activation value of the first neuron\n",
    "        img[i, j] = A3[0]\n",
    "        \n",
    "        # plot\n",
    "        if A3[0] > 0.5: # class 1\n",
    "            plt.plot(pos[i], pos[j], 'ro', alpha=0.2, label='class 1')\n",
    "        else: # class 2\n",
    "            plt.plot(pos[i], pos[j], 'bo', alpha=0.2, label='class 2')\n",
    "\n",
    "# final plot\n",
    "plt.plot([1, -1], [1, -1], 'ro')\n",
    "plt.plot([-1, 1], [1, -1], 'bo')\n",
    "plt.show()\n",
    "\n",
    "# normalize and resize the image\n",
    "img = cv2.normalize(img, None, 0, 255, cv2.NORM_MINMAX)\n",
    "img = cv2.flip(img, 1) # y axis in image points downwards\n",
    "img = cv2.resize(img, (0, 0), fx=16, fy=16, interpolation=cv2.INTER_NEAREST)\n",
    "\n",
    "print(\"Decision surface:\")\n",
    "plot_img_orig(img)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "name": "exercise03.ipynb",
   "provenance": [
    {
     "file_id": "1t83LvQEqlSn19-1lIXfkp-R22qZd_lSK",
     "timestamp": 1586447633533
    }
   ],
   "toc_visible": true
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
